from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
import pandas as pd
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import joblib

# Conexão com o banco de dados
DATABASE_URI = 'postgresql+psycopg2://postgres:1408@localhost/cars_dataset'
engine = create_engine(DATABASE_URI)
Session = sessionmaker(bind=engine)

# Carregar dados do banco de dados
def carregar_dados():
    session = Session()
    query = """
    SELECT vf_modelyear AS ano, brandname AS marca, askprice AS preco
    FROM cars
    WHERE askprice IS NOT NULL
    LIMIT 1000;
    """
    df = pd.read_sql(query, session.bind)
    session.close()

    # Tratar a coluna de ano
    df['ano'] = pd.to_datetime(df['ano'], errors='coerce').dt.year
    return df.dropna(subset=['ano', 'marca', 'preco'])

data = carregar_dados()

# Separar variáveis independentes (X) e dependente (y)
X = data[['ano', 'marca']]
y = data['preco']

# Filtrar marcas com pelo menos 2 exemplos
marca_counts = X['marca'].value_counts()
marcas_validas = marca_counts[marca_counts > 1].index
X = X[X['marca'].isin(marcas_validas)]
y = y[X.index]

# Pré-processamento com pipeline
numeric_features = ['ano']
categorical_features = ['marca']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

# Modelo
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(random_state=42))
])

# Divisão estratificada
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(X, X['marca']):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

# Treinar modelo
model.fit(X_train, y_train)

# Avaliar modelo
y_pred = model.predict(X_test)
rmse = mean_squared_error(y_test, y_pred, squared=False)  # Usando mean_squared_error para RMSE
print(f"RMSE: {rmse}")

# Salvar modelo
joblib.dump(model, 'modelo_previsao_veiculos_com_pipeline.pkl')
print("Modelo salvo com sucesso!")
